\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{}
\citation{}
\citation{mintz2009distant,zeng2015distant}
\select@language{american}
\@writefile{toc}{\select@language{american}}
\@writefile{lof}{\select@language{american}}
\@writefile{lot}{\select@language{american}}
\citation{ahn2006stages,li2013joint,chen2015event,nguyen2016joint}
\citation{huang2015bidirectional,lample2016neural}
\citation{bollacker2008freebase}
\newlabel{fig:3}{{1}{2}{Examples of a CVT table in Freebase, and labeled sentences in our dataset. \emph {Company\_acquired}, \emph {acquiring\_company} and \emph {date} are key arguments in \emph {business.acquisition}}{figure.1}{}}
\newlabel{datagen}{{2.3}{3}{Dataset Construction}{subsection.2.3}{}}
\newlabel{fig:2}{{2}{3}{An illustration of dependency tree of S4, which partially matches an entry of \emph {people.marriage}}{figure.2}{}}
\citation{hochreiter1997long}
\citation{collobert2011natural,huang2015bidirectional}
\citation{rabiner1989tutorial}
\newlabel{evede}{{3.1}{4}{Event Detection}{subsection.3.1}{}}
\citation{gurobi}
\citation{mikolov2013distributed}
\newlabel{statistics}{{1}{5}{Statistics for the generated dataset. \emph {\#Sent.} is the number of sentences, \emph {\#Eve.} is the number of event mentions, and \emph {\#Arg.} is the number of event arguments. \emph {\%Multi\_Eve.} is the ratio of multi-type events}{table.1}{}}
\newlabel{sec:evalhypo}{{4.2}{5}{Dataset Evaluation}{subsection.4.2}{}}
\citation{lafferty2001conditional}
\citation{berger1996maximum}
\citation{li2013joint}
\citation{manning2014stanford}
\citation{kudo2005crf++}
\newlabel{tab:3}{{2}{6}{Statistic of the datasets built with different strategies. \textit {Dataset} is the number of sentences found. \textit {Type} indicates the number of different CVT types in each dataset. \textit {Pos} is the percentage of sentences mentioning the given events explicitly}{table.2}{}}
\newlabel{tab:1}{{3}{7}{Overall system performance of automatic evaluations. (\%)}{table.3}{}}
\newlabel{manualeve}{{4.5}{7}{Manual Evaluation}{subsection.4.5}{}}
\newlabel{tab:2}{{4}{7}{Average of F1 scores of system performance of manual evaluations by two annotators. EC, AD, ED denote the event classification, argument detection and event detection, respectively}{table.4}{}}
\newlabel{fig:1}{{3}{7}{Example outputs of LSTM-CRF-ILP$_{multi}$}{figure.3}{}}
\citation{grishman1996message}
\citation{doddington2004automatic}
\citation{song2015light}
\citation{mitamura2015event}
\citation{gupta2009predicting,hong2011using,li2013joint}
\citation{chen2015event,nguyen2016joint}
\citation{huang2016liberal}
\citation{mintz2009distant}
\newlabel{tab:4}{{5}{8}{Top 5 event types whose performances on event classification differ most from automatic evaluation. The evaluated model is LSTM-CRF-ILP$_{multi}$}{table.5}{}}
\newlabel{tab:6}{{6}{8}{Statistics of the dataset and overall performance of our LSTM-CRF-ILP$_{multi}$ model. \textit {Table size} is the number of table entries. \textit {Dataset} is the size of training set}{table.6}{}}
\bibdata{emnlp2017}
\bibcite{ahn2006stages}{{1}{2006}{{Ahn}}{{}}}
\bibcite{berger1996maximum}{{2}{1996}{{Berger et~al.}}{{Berger, Pietra, and Pietra}}}
\bibcite{bollacker2008freebase}{{3}{2008}{{Bollacker et~al.}}{{Bollacker, Evans, Paritosh, Sturge, and Taylor}}}
\bibcite{chen2015event}{{4}{2015}{{Chen et~al.}}{{Chen, Xu, Liu, Zeng, and Zhao}}}
\bibcite{collobert2011natural}{{5}{2011}{{Collobert et~al.}}{{Collobert, Weston, Bottou, Karlen, Kavukcuoglu, and Kuksa}}}
\bibcite{doddington2004automatic}{{6}{2004}{{Doddington et~al.}}{{Doddington, Mitchell, Przybocki, Ramshaw, Strassel, and Weischedel}}}
\bibcite{grishman1996message}{{7}{1996}{{Grishman and Sundheim}}{{}}}
\bibcite{gupta2009predicting}{{8}{2009}{{Gupta and Ji}}{{}}}
\bibcite{gurobi}{{9}{2016}{{Gurobi~Optimization}}{{}}}
\bibcite{hochreiter1997long}{{10}{1997}{{Hochreiter and Schmidhuber}}{{}}}
\bibcite{hong2011using}{{11}{2011}{{Hong et~al.}}{{Hong, Zhang, Ma, Yao, Zhou, and Zhu}}}
\bibcite{huang2016liberal}{{12}{2016}{{Huang et~al.}}{{Huang, Cassidy, Feng, Ji, Voss, Han, and Sil}}}
\bibcite{huang2015bidirectional}{{13}{2015}{{Huang et~al.}}{{Huang, Xu, and Yu}}}
\bibcite{kudo2005crf++}{{14}{2005}{{Kudo}}{{}}}
\bibcite{lafferty2001conditional}{{15}{2001}{{Lafferty et~al.}}{{Lafferty, McCallum, and Pereira}}}
\bibcite{lample2016neural}{{16}{2016}{{Lample et~al.}}{{Lample, Ballesteros, Subramanian, Kawakami, and Dyer}}}
\bibcite{li2013joint}{{17}{2013}{{Li et~al.}}{{Li, Ji, and Huang}}}
\bibcite{manning2014stanford}{{18}{2014}{{Manning et~al.}}{{Manning, Surdeanu, Bauer, Finkel, Bethard, and McClosky}}}
\bibcite{mikolov2013distributed}{{19}{2013}{{Mikolov et~al.}}{{Mikolov, Sutskever, Chen, Corrado, and Dean}}}
\bibcite{mintz2009distant}{{20}{2009}{{Mintz et~al.}}{{Mintz, Bills, Snow, and Jurafsky}}}
\bibcite{mitamura2015event}{{21}{2015}{{Mitamura et~al.}}{{Mitamura, Yamakawa, Holm, Song, Bies, Kulick, and Strassel}}}
\bibcite{nguyen2016joint}{{22}{2016}{{Nguyen et~al.}}{{Nguyen, Cho, and Grishman}}}
\bibcite{rabiner1989tutorial}{{23}{1989}{{Rabiner}}{{}}}
\bibcite{song2015light}{{24}{2015}{{Song et~al.}}{{Song, Bies, Strassel, Riese, Mott, Ellis, Wright, Kulick, Ryant, and Ma}}}
\bibcite{zeng2015distant}{{25}{2015}{{Zeng et~al.}}{{Zeng, Liu, Chen, and Zhao}}}
\bibstyle{emnlp_natbib}
